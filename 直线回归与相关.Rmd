---
title: "直线回归与相关"
author: "shydow"
date: "2018年12月18日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###学习目标

**直线相关的定义，熟悉简单相关系数的计算，以及R程序**  
**直线回归的模型假设以及计算方法，回归应用的注意事项，以及R程序**  

###内容概要

**相关分析和回归分析是研究现象之间的相关关系的两种基本方法**  
  
**直线回归分析的任务是找出两个变量之间由依存关系的直线方程，以确定一条最接近于各实测点的直线，使各实测点与该直线的纵向距离的平方和为最小**  

##直线相关分析

    1、按相关程度划分，可分为完全相关、不完全相关和不相关
    --不相关：变量之间彼此的数量变化完全独立
    --完全相关：一个变量的变化是由其他变量的数量变化所唯一确定的
    --不完全相关：介于不相关与完全相关之间
    
    2、按相关方向进行划分，可分为正相关和负相关
    
    3、按相关的形式进行划分，可分为线性相关和非线性相关
    
    相关分析：分析测定变量之间相互依存关系的密切程度的统计方法，可以用相关系数、相关表、相关图表示。
    

**在R中进行相关分析的过程步时cor()函数，cor()函数可以用来计算多种相关系数，包括Pearson系数、Spearman相关系数、Kendall相关系数、偏相关系数、多分格相关系数。**

--***Pearson积差系数***：两个定量变量之间的线性相关程度，用于双变量正态分布资料  
--***Spaerman等级相关系数***：衡量分级定序变量之间的相关程度

    cor()函数格式：
    cor(x, use= , method=)
    
    --x:矩阵或者数据框
    --use: 指定缺失数据的处理方式，可选方式：all.obs（报错）；everything（missing）；complete.obs（行删除）
    --method: pearson,spearman

    
在计算好相关系数之后，需要对变量进行统计显著性检验。原假设为变量间的不相关（总体相关系数为0），可以使用**cor.test()函数**对单个的Pearson、Spearman系数进行检验。

    cor.test()函数格式：
    cor.test(x,y,alternative=,method=)
    
    --x,y要检验相关性的变量
    --alternative用来指定单侧检验还是双侧检验
    --method指定相关类型（pearson，spearmen）

  
案例1：
    表9-3       10名孕妇分娩时TSH水平
    母血    1.21 1.30 1.39 1.42 1.47 1.56 1.68 1.72 1.98 2.10
    脐带血  3.90 4.50 4.20 4.83 4.16 4.93 4.32 4.99 4.70 5.20
    
```{r}
example9_1<-read.csv('F:\\课件\\资源\\《R语言统计分析与应用》配套程序\\第九章\\example9_1.csv',header=TRUE)
attach(example9_1)

plot(x1,x2)
cor(example9_1,method = 'pearson')
cor.test(x1,x2,method = 'pearson')
detach(example9_1)
```
    
    
案例2：--spearman相关系数，用于分级定序变量
    表9-4            职工的销售潜能与销售成绩的秩相关分析
    潜能等级                  销售成绩
    2                            400
    4                            360
    7                            300
    1                            295
    6                            280
    3                            350
    10                           200
    9                            260
    8                            220
    5                            385
    
```{r}
example9_3<-read.csv('F:\\课件\\资源\\《R语言统计分析与应用》配套程序\\第九章\\example9_3.csv',header=TRUE)
attach(example9_3)

cor(example9_3,method = 'spearman')
cor.test(x,y,method = 'spearman')
detach(example9_3)
```
    
    
    
##直线回归分析

###直线回归分析介绍

**直线回归是用直线回归方程表示两个数量变量间的依存关系的统计分析方法，属于双变量分析的范畴。如果某一个变量随着另一个变量的变化而变化，并且他们的变化在直角坐标系中呈直线趋势，就可以用一个直线方程来定量的描述他们之间的数量依存关系**  

**所谓的回归分析，就是依据相关关系的具体形态，选择一个合适的数学模型，来近似地表达变量间的平均关系**  

    一元线性回归格式：
    Y是X的线性函数加上误差项，线性部分反映了由于X的变化引起Y的变化；误差项是随机变量，反映了除了X和Y之间线性关系之外随机因素对Y的影响，不能由X和Y之间的变异线性关系所解释的变异性。
    
    模型表达式： Y=a+bX+误差项
    
    一元线性回归的基本假设：
    1、误差项是一个期望值为0的随机变量，对于一个给定的X值，Y的期望值等于： a+bX
    2、对于所有的X值，误差项的方差都相同
    3、误差项是一个服从正态分布的随机变量，且相互独立
    
    模型参数估计使用最小二乘法：即使因变量的观察值与估计值之间离差平方和达到最小来求得a和b的方法
    
    回归方程的检验包括：
    1、拟合度检验（R方）
    R方=1-（观测值和估计值的离差平方和/估计值与均值的离差平方和）
    
    2、回归方程的显著性检验
    将回归离差平方和和同剩余离差平方和加以比较，应用F检验分析二者之间的差别是否显著。
    
    3、回归系数的显著性检验
    

###直线回归案例

**lm()函数只是R中一个众多关于回归的函数之一，lm()函数用于一般目的的回归分析函数**  

**格式为： myfit<-lm(formula,data)   formula:拟合的模型形式，data： 数据框 **

    R中常用的拟合模型有用的函数：
    
    --summary() :展示详细的模型拟合结果
    --anova() ：生成方差分析表
    --plot() :拟合模型的诊断图


案例：体重与心脏横劲的关系  

```{r}
example9_4<-read.csv('F:\\课件\\资源\\《R语言统计分析与应用》配套程序\\第九章\\example9_4.csv',header=TRUE)
head(example9_4)

attach(example9_4)
plot(x,y)

fit<-lm(y~x)
anova(fit)
summary(fit)

```
    


    
